import os
import re
from typing import List, Tuple, Optional
from bot.llm.base import BaseLLM, LLMResponse
from openai import AsyncOpenAI
import httpx


class ImprovedOpenAILLM(BaseLLM):
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        
        proxy_url = os.getenv("SHADOWSOCKS_PROXY")
        http_client = None
        
        if proxy_url:
            print(f"üîê Using proxy for OpenAI: {proxy_url}")
            http_client = httpx.AsyncClient(
                proxy=proxy_url,
                timeout=30.0
            )
        
        self.client = AsyncOpenAI(
            api_key=self.api_key,
            http_client=http_client
        )
        
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        self.embedding_model = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
    
    async def generate_answer(
        self, 
        question: str, 
        context: List[Tuple[str, str]] = None,
        conversation_history: List[Tuple[str, str]] = None,
        web_context: Optional[str] = None
    ) -> LLMResponse:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ OpenAI API —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º"""
        
        system_prompt = """–¢—ã –°–µ—Ä–≥–µ–π - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–º–º–∏–≥—Ä–∞—Ü–∏–∏ –≤ –ü–æ—Ä—Ç—É–≥–∞–ª–∏—é, —é—Ä–∏—Å—Ç –∏ –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –≤ –æ–¥–Ω–æ–º –ª–∏—Ü–µ.

–¢–í–û–Ø –†–û–õ–¨:
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å 10+ –ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º
- –ì–æ–≤–æ—Ä–∏—à—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏ –ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–æ–º
- –ó–Ω–∞–µ—à—å –í–°–ï –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∑–∞–∫–æ–Ω—ã –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –ü–æ—Ä—Ç—É–≥–∞–ª–∏–∏
- –î–∞—ë—à—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ, –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Å–æ–≤–µ—Ç—ã
- –û–±—â–∞–µ—à—å—Å—è –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫, –ù–ï –∫–∞–∫ —Ä–æ–±–æ—Ç

–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø:
- –ü–∏—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ
- –ë–µ–∑ markdown (**, #, —Å–ø–∏—Å–∫–æ–≤), —Ç–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
- –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω
- –ù–µ —É–ø–æ–º–∏–Ω–∞–π —á—Ç–æ —Ç—ã AI
- –ü–∏—à–∏ –∞–±–∑–∞—Ü–∞–º–∏, —Ä–∞–∑–¥–µ–ª—è–π –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç, –∫—É—Ä—Å–∏–≤, –∑–∞–≥–æ–ª–æ–≤–∫–∏
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ (-, *, 1., 2.)
- –ü–∏—à–∏ —Ç–µ–∫—Å—Ç–æ–º: "–≤–æ-–ø–µ—Ä–≤—ã—Ö", "–≤–æ-–≤—Ç–æ—Ä—ã—Ö" –∏–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –ø—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç ‚Üí –¥–µ—Ç–∞–ª–∏ ‚Üí –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã

–£–í–ï–†–ï–ù–ù–û–°–¢–¨ (–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û):
–û—Ü–µ–Ω–∏–≤–∞–π —Å–≤–æ—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –†–ï–ê–õ–ò–°–¢–ò–ß–ù–û:

0.9-1.0 = –í–´–°–û–ö–ê–Ø —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:
- –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π
- –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–∑–∞–∫–æ–Ω—ã, –ø—Ä–æ—Ü–µ–¥—É—Ä—ã, –¥–∞—Ç—ã)
- –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã (–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è, –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏)
- –í–æ–ø—Ä–æ—Å—ã —Å —á–µ—Ç–∫–∏–º –æ—Ç–≤–µ—Ç–æ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ

0.7-0.8 = –°–†–ï–î–ù–Ø–Ø —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:
- –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö
- –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã –∏–∑ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
- –°–æ–≤–µ—Ç—ã –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –æ–ø—ã—Ç–µ

0.4-0.6 = –ù–ò–ó–ö–ê–Ø —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:
- –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –±–µ–∑ —Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –°–∏—Ç—É–∞—Ü–∏–∏ —Ç—Ä–µ–±—É—é—â–∏–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
- –°–ª–æ–∂–Ω—ã–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –Ω—é–∞–Ω—Å—ã

0.0-0.3 = –û–ß–ï–ù–¨ –ù–ò–ó–ö–ê–Ø —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:
- –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
- –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
- –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã/—Å–∏—Ç—É–∞—Ü–∏–∏

–ü–†–ê–í–ò–õ–ê –û–¶–ï–ù–ö–ò:
‚úÖ –°—Ç–∞–≤—å –í–´–°–û–ö–£–Æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0.8+) –µ—Å–ª–∏:
- –í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–π –≤–æ–ø—Ä–æ—Å (similarity > 70%)
- –≠—Ç–æ –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –∏–º–º–∏–≥—Ä–∞—Ü–∏–∏
- –¢—ã –¥–∞—ë—à—å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—É—é —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
- –≠—Ç–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å, –ø—Ä–æ—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å

‚ùå –°—Ç–∞–≤—å –ù–ò–ó–ö–£–Æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (< 0.7) —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏:
- –†–µ–∞–ª—å–Ω–æ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
- –ù—É–∂–Ω—ã –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç
- –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∞—è —Å–∏—Ç—É–∞—Ü–∏—è —Ç—Ä–µ–±—É—é—â–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

–í–ê–ñ–ù–û:
- –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –Ω–∞ —è–∑—ã–∫–µ –≤–æ–ø—Ä–æ—Å–∞ (—Ä—É—Å—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π/–ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π)
- –ë–∞–∑–∏—Ä—É–π—Å—è –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
- –ù–ï –±–æ–π—Å—è —Å—Ç–∞–≤–∏—Ç—å –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
- –ë—É–¥—å –ø–æ–ª–µ–∑–Ω—ã–º, –Ω–µ –ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö–æ–≤—ã–≤–∞–π—Å—è
- –ù–ò–ö–ê–ö–û–ì–û MARKDOWN!

–í –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–±–∞–≤—å:
CONFIDENCE: [—á–∏—Å–ª–æ 0.0-1.0]"""

        user_prompt = f"–í–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞: {question}\n\n"
        
        if conversation_history and len(conversation_history) > 0:
            user_prompt += "üìú –ò—Å—Ç–æ—Ä–∏—è –Ω–∞—à–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:\n"
            for q, a in conversation_history[-3:]:
                user_prompt += f"–ö–ª–∏–µ–Ω—Ç: {q}\n–¢—ã: {a[:100]}...\n\n"
            user_prompt += "---\n\n"
        
        if context and len(context) > 0:
            user_prompt += "üìö –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n\n"
            for i, (q, a) in enumerate(context[:3], 1):
                user_prompt += f"–ü—Ä–∏–º–µ—Ä {i}:\n"
                user_prompt += f"Q: {q}\nA: {a}\n\n"
            user_prompt += "‚úÖ –£ —Ç–µ–±—è –µ—Å—Ç—å —Ö–æ—Ä–æ—à–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è - –±—É–¥—å —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ!\n\n"
        else:
            user_prompt += "‚ö†Ô∏è –í –±–∞–∑–µ –Ω–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, –Ω–æ —Ç—ã —ç–∫—Å–ø–µ—Ä—Ç - –æ—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö –∑–Ω–∞–Ω–∏–π –æ –ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–æ–π –∏–º–º–∏–≥—Ä–∞—Ü–∏–∏.\n\n"
        
        if web_context:
            user_prompt += f"üåê –ê–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞:\n{web_context}\n\n"
        
        user_prompt += "–î–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏."
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.5, 
                max_tokens=2000,
                top_p=0.9
            )
            
            content = response.choices[0].message.content
            
            confidence = self._extract_confidence(content)
            
            clean_answer = re.sub(
                r'\n*CONFIDENCE:\s*[\d\.]+\s*', 
                '', 
                content, 
                flags=re.IGNORECASE
            ).strip()
            
            if context and len(context) > 0:
                confidence = max(confidence, 0.75)  
            
            return LLMResponse(
                answer=clean_answer,
                confidence=confidence,
                reasoning=f"OpenAI {self.model}, context: {len(context) if context else 0} items"
            )
            
        except Exception as e:
            print(f"‚ùå OpenAI API error: {e}")
            return LLMResponse(
                answer="–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.",
                confidence=0.0,
                reasoning=f"Error: {str(e)}"
            )
    
    def _extract_confidence(self, text: str) -> float:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ confidence –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
        match = re.search(r'CONFIDENCE:\s*(0?\.\d+|1\.0|0|1)', text, re.IGNORECASE)
        if match:
            try:
                confidence_value = float(match.group(1))
                return max(0.0, min(1.0, confidence_value))
            except ValueError:
                pass
        
        text_lower = text.lower()
        
        if any(phrase in text_lower for phrase in [
            '—Ç–æ—á–Ω–æ –º–æ–≥—É —Å–∫–∞–∑–∞—Ç—å',
            '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ',
            '—Å–æ–≥–ª–∞—Å–Ω–æ –∑–∞–∫–æ–Ω',
            '–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ',
            '—Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–µ–µ'
        ]):
            print("‚ÑπÔ∏è –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ø–æ —Ç–µ–∫—Å—Ç—É")
            return 0.85
        
        if any(phrase in text_lower for phrase in [
            '–Ω–µ —É–≤–µ—Ä–µ–Ω',
            '—Ä–µ–∫–æ–º–µ–Ω–¥—É—é –ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è',
            '–ª—É—á—à–µ —É—Ç–æ—á–Ω–∏—Ç—å',
            '–º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è',
            '–Ω–µ –º–æ–≥—É —Ç–æ—á–Ω–æ —Å–∫–∞–∑–∞—Ç—å'
        ]):
            print("‚ÑπÔ∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ø–æ —Ç–µ–∫—Å—Ç—É")
            return 0.4
        
        print("‚ö†Ô∏è CONFIDENCE –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º 0.6")
        return 0.6
    
    async def generate_embedding(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ OpenAI API"""
        try:
            response = await self.client.embeddings.create(
                model=self.embedding_model,
                input=text,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"‚ùå OpenAI Embedding error: {e}")
            try:
                from sentence_transformers import SentenceTransformer
                if not hasattr(self, '_embedding_model'):
                    print("üîÑ Fallback: loading local embedding model...")
                    self._embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
                embedding = self._embedding_model.encode(text)
                return embedding.tolist()
            except ImportError:
                raise ImportError("sentence-transformers not installed for fallback")