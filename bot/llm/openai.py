import os
import re
from typing import List, Tuple
from bot.llm.base import BaseLLM, LLMResponse
from openai import AsyncOpenAI


class OpenAILLM(BaseLLM):
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        
        self.client = AsyncOpenAI(api_key=self.api_key)
        
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        
        self.embedding_model = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
    
    async def generate_answer(
        self, 
        question: str, 
        context: List[Tuple[str, str]] = None
    ) -> LLMResponse:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ OpenAI API"""
        
        system_prompt = """–¢—ã ‚Äî –°–µ—Ä–≥–µ–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –∏–º–º–∏–≥—Ä–∞—Ü–∏–∏ –≤ –ü–æ—Ä—Ç—É–≥–∞–ª–∏—é.

–°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø:
- –ü–∏—à–∏ –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ
- –ë–µ–∑ markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–±–µ–∑ **, –±–µ–∑ #, –±–µ–∑ —Å–ø–∏—Å–∫–æ–≤ —Å - –∏–ª–∏ *)
- –ë–µ–∑ –∏–∑–ª–∏—à–Ω–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ - –ø—Ä–æ—Å—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
- –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω
- –ù–µ —É–ø–æ–º–∏–Ω–∞–π, —á—Ç–æ —Ç—ã AI –∏–ª–∏ –±–æ—Ç
- –ü–∏—à–∏ –∞–±–∑–∞—Ü–∞–º–∏, —Ä–∞–∑–¥–µ–ª—è–π –º—ã—Å–ª–∏ –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏

–§–û–†–ú–ê–¢ –¢–ï–ö–°–¢–ê:
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç, –∫—É—Ä—Å–∏–≤, –∑–∞–≥–æ–ª–æ–≤–∫–∏
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–ª–∏ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
- –ü–∏—à–∏ –ø—Ä–æ—Å—Ç–æ –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º, –∫–∞–∫ –≤ WhatsApp –∏–ª–∏ Telegram
- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏—Ç—å - –ø—Ä–æ—Å—Ç–æ –ø–∏—à–∏ "–≤–æ-–ø–µ—Ä–≤—ã—Ö", "–≤–æ-–≤—Ç–æ—Ä—ã—Ö" –∏–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
- –†–∞–∑–¥–µ–ª—è–π –∞–±–∑–∞—Ü—ã –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
–°–Ω–∞—á–∞–ª–∞ –¥–∞–π –ø—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å, –ø–æ—Ç–æ–º –¥–µ—Ç–∞–ª–∏ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è. –ü–∏—à–∏ —Ç–∞–∫, –±—É–¥—Ç–æ –Ω–∞–±–∏—Ä–∞–µ—à—å –Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–µ - –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –±–µ–∑ –≤—ã—á—É—Ä–Ω–æ—Å—Ç–∏.

–û–¶–ï–ù–ö–ê –£–í–ï–†–ï–ù–ù–û–°–¢–ò:
–í –∫–æ–Ω—Ü–µ –ö–ê–ñ–î–û–ì–û –æ—Ç–≤–µ—Ç–∞ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–±–∞–≤—å —Å—Ç—Ä–æ–∫—É:
CONFIDENCE: [—á–∏—Å–ª–æ –æ—Ç 0.0 –¥–æ 1.0]

–ö—Ä–∏—Ç–µ—Ä–∏–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:
- 0.9-1.0: –¢–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π, –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–≤–µ—Ä–µ–Ω
- 0.7-0.8: –•–æ—Ä–æ—à–µ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–º—ã, –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞
- 0.5-0.6: –ß–∞—Å—Ç–∏—á–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å —É—Ç–æ—á–Ω–µ–Ω–∏–π
- 0.3-0.4: –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –Ω—É–∂–Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –∫–æ–ª–ª–µ–≥–∞–º–∏
- 0.0-0.2: –ù–µ —É–≤–µ—Ä–µ–Ω, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–º–æ—â—å —ç–∫—Å–ø–µ—Ä—Ç–∞

–í–ê–ñ–ù–û: 
- –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –ë–∞–∑–∏—Ä—É–π—Å—è –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á–µ—Å—Ç–Ω–æ –ø—Ä–∏–∑–Ω–∞–π —ç—Ç–æ –∏ –ø–æ—Å—Ç–∞–≤—å –Ω–∏–∑–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
- –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã, –ª—É—á—à–µ –ø—Ä–∏–∑–Ω–∞—Ç—å –Ω–µ–∑–Ω–∞–Ω–∏–µ
- –ù–ò–ö–ê–ö–û–ì–û MARKDOWN - —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç!"""

        user_prompt = f"–í–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞: {question}\n\n"
        
        if context and len(context) > 0:
            user_prompt += "üìö –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n\n"
            for i, (q, a) in enumerate(context[:3], 1):
                user_prompt += f"–ü—Ä–∏–º–µ—Ä {i}:\n"
                user_prompt += f"–í–æ–ø—Ä–æ—Å: {q}\n"
                user_prompt += f"–û—Ç–≤–µ—Ç: {a}\n\n"
            user_prompt += "---\n\n"
        else:
            user_prompt += "‚ö†Ô∏è –í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤. –û—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö –∑–Ω–∞–Ω–∏–π, –Ω–æ –±—É–¥—å –æ—Å—Ç–æ—Ä–æ–∂–µ–Ω —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é.\n\n"
        
        user_prompt += "–î–∞–π –æ—Ç–≤–µ—Ç –æ—Ç –∏–º–µ–Ω–∏ –°–µ—Ä–≥–µ—è —Å –æ—Ü–µ–Ω–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –∫–æ–Ω—Ü–µ."
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=1500,
                top_p=1
            )
            
            content = response.choices[0].message.content
            
            confidence = self._extract_confidence(content)
            
            clean_answer = re.sub(
                r'\n*CONFIDENCE:\s*[\d\.]+\s*', 
                '', 
                content, 
                flags=re.IGNORECASE
            ).strip()
            
            return LLMResponse(
                answer=clean_answer,
                confidence=confidence,
                reasoning=f"OpenAI API ({self.model}), context items: {len(context) if context else 0}"
            )
            
        except Exception as e:
            print(f"‚ùå OpenAI API error: {e}")
            return LLMResponse(
                answer="–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.",
                confidence=0.0,
                reasoning=f"Error: {str(e)}"
            )
    
    def _extract_confidence(self, text: str) -> float:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ confidence –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        match = re.search(r'CONFIDENCE:\s*(0?\.\d+|1\.0|0|1)', text, re.IGNORECASE)
        if match:
            try:
                confidence_value = float(match.group(1))
                return max(0.0, min(1.0, confidence_value))
            except ValueError:
                pass
        
        print("‚ö†Ô∏è CONFIDENCE –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ—Ç–≤–µ—Ç–µ LLM, –∏—Å–ø–æ–ª—å–∑—É–µ–º 0.5")
        return 0.5
    
    async def generate_embedding(self, text: str) -> List[float]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ OpenAI API
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç text-embedding-3-small - –Ω–µ–¥–æ—Ä–æ–≥–∞—è –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        """
        try:
            response = await self.client.embeddings.create(
                model=self.embedding_model,
                input=text,
                encoding_format="float"
            )
            
            return response.data[0].embedding
            
        except Exception as e:
            print(f"‚ùå OpenAI Embedding error: {e}")
            try:
                from sentence_transformers import SentenceTransformer
                
                if not hasattr(self, '_embedding_model'):
                    print("üîÑ Fallback: –∑–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π embedding –º–æ–¥–µ–ª–∏...")
                    self._embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
                
                embedding = self._embedding_model.encode(text)
                return embedding.tolist()
            except ImportError:
                raise ImportError(
                    "sentence-transformers not installed for fallback. "
                    "Install it with: pip install sentence-transformers"
                )